{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-26 11:32:08.818610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-26 11:32:08.988242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-26 11:32:08.988270: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-26 11:32:09.015336: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-26 11:32:09.691932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-26 11:32:09.691989: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-26 11:32:09.691997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_braunfels_data_path = os.path.join(\"..\",\"input_data\",\"array_input\",\"New_Braunfels.npy\")\n",
    "del_rio_data_path = os.path.join(\"..\",\"input_data\",\"array_input\",\"Del_rio_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_rio_history = np.load(del_rio_data_path)\n",
    "New_Braunfels_history = np.load(new_braunfels_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 138, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(New_Braunfels_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_arr(history):\n",
    "    time_arr = []\n",
    "    for j in range(64):\n",
    "        for i in range(64):\n",
    "            arr = []\n",
    "            for l in range(history.shape[1]):\n",
    "                arr.append(history[0][l][j][i])\n",
    "            time_arr.append(arr)\n",
    "    return time_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_braunfels_time_arr = make_time_arr(New_Braunfels_history)\n",
    "del_rio__time_arr = make_time_arr(del_rio_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "print(len(new_braunfels_time_arr[0]))\n",
    "print(len(del_rio__time_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 138)\n",
      "(4096, 186)\n"
     ]
    }
   ],
   "source": [
    "new_braunfels_data = np.array(new_braunfels_time_arr)\n",
    "del_rio_data = np.array(del_rio__time_arr)\n",
    "print(new_braunfels_data.shape)\n",
    "print(del_rio_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(data):\n",
    "    for i in range(0,len(data),32):\n",
    "        batch = data[i:i+32]\n",
    "        batch_reshaped = np.reshape(batch, (batch.shape[0], batch.shape[1], 1))\n",
    "        lstm = tf.keras.layers.LSTM(10)\n",
    "        output = lstm(batch_reshaped)\n",
    "        \n",
    "        dense_nn = tf.keras.layers.Dense(1)\n",
    "        output = dense_nn(output)\n",
    "        if i==0:\n",
    "            prediction = np.array(output)\n",
    "        else:\n",
    "            prediction = np.concatenate((prediction,output), axis = 0)\n",
    "    print(prediction.shape)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1)\n",
      "(4096, 1)\n"
     ]
    }
   ],
   "source": [
    "new_braunfels_prediction = LSTM_model(new_braunfels_data[:,:-1])\n",
    "del_rio_prediction = LSTM_model(del_rio_data[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(A,B):\n",
    "    mse = mean_squared_error(A, B)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[[-0.00063613]\n",
      " [-0.00077811]\n",
      " [-0.00078349]\n",
      " ...\n",
      " [-0.00056113]\n",
      " [-0.00019311]\n",
      " [ 0.00131933]]\n"
     ]
    }
   ],
   "source": [
    "print(new_braunfels_data[:,-1])\n",
    "print(new_braunfels_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028888786222031806 0.0005028951479690945\n"
     ]
    }
   ],
   "source": [
    "new_braunfels_mse = mse(new_braunfels_data[:,-1], new_braunfels_prediction)\n",
    "del_rio_mse = mse(del_rio_data[:,-1], del_rio_prediction)\n",
    "print(new_braunfels_mse, del_rio_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_braunfels_prediction = np.reshape(new_braunfels_prediction,(64,64))\n",
    "# del_rio_prediction = np.reshape(del_rio_prediction,(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial Evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(10),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer=\"Adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalCrossentropy()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "out = model(np.reshape(new_braunfels_data[:3000,:-1], (new_braunfels_data[:3000,:-1].shape[0], new_braunfels_data[:3000,:-1].shape[1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000,), TensorShape([3000, 1]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3000,), dtype=float32, numpy=\n",
       "array([0.2491291 , 0.24912259, 0.24938166, ..., 0.24480188, 0.24533348,\n",
       "       0.24399492], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.mse(y_true.reshape(-1, 1), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3000,), dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.categorical_crossentropy(y_true.reshape(-1, 1), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3000, 1), dtype=float32, numpy=\n",
       "array([[0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       ...,\n",
       "       [0.99999994],\n",
       "       [0.99999994],\n",
       "       [0.99999994]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = new_braunfels_data[:3000,-1]\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_ones = np.ones(3000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 137, 1)\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00\n",
      "Epoch 1: saving model to training_1/cp.ckpt\n",
      "94/94 [==============================] - 5s 30ms/step - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f34d1850940>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "\n",
    "lstm_model = create_model()\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "batch_reshaped = np.reshape(new_braunfels_data[:3000,:-1], (new_braunfels_data[:3000,:-1].shape[0], new_braunfels_data[:3000,:-1].shape[1], 1))\n",
    "print(batch_reshaped.shape)\n",
    "lstm_model.fit(batch_reshaped, y_true_ones,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 1s - loss: 1.5418e-04 - mae: 0.0091 - 1s/epoch - 11ms/step\n",
      "Untrained model, accuracy:  0.91%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = lstm_model.evaluate(batch_reshaped, new_braunfels_data[:3000,-1], verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 - 1s - loss: 3.1826e-04 - mae: 0.0137 - 945ms/epoch - 27ms/step\n",
      "Untrained model, accuracy:  1.37%\n"
     ]
    }
   ],
   "source": [
    "lstm_validation_model = create_model()\n",
    "lstm_validation_model.load_weights(checkpoint_path)\n",
    "\n",
    "batch_reshaped = np.reshape(new_braunfels_data[3000:,:-1], (new_braunfels_data[3000:,:-1].shape[0], new_braunfels_data[3000:,:-1].shape[1], 1))\n",
    "\n",
    "loss, acc = lstm_validation_model.evaluate(batch_reshaped, new_braunfels_data[3000:,-1], verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('BTP': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "577482fee326091ea713db108c300d8621cb63b99a9d09a960c56d7fa44a7ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
